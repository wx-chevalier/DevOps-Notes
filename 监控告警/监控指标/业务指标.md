# 监控指标

在系统的质量保障中，我们常常希望能实现所谓的立体化监控，实时感知，提前预警。但是越全面，成本越高。所以，根据所处的时期从中挑选合适的监控方式更加重要。本节即着重讨论我们在搭建监控体系时候的指标考量。

## 基础指标

## Google 的四个黄金指标

对于监控指标，我们可以有很多种的划分方式。其一即根据目标来划分，将其分为系统指标、程序指标、业务指标等。

- 系统指标主要是网络 IO、网络延迟、磁盘 IO、磁盘占用大小、CPU 使用率、内存使用率、交换分区等等。

- 程序指标除了和系统指标一样的 CPU 使用率、内存使用率这种外部表现的指标之外，还有应用程序错误数、应用程序请求量、应用平均响应时间这种内部表现的指标；对于程序指标的落地我们常常就会徘徊于侵入式与非侵入式两种。

- 业务指标即每一个业务会经过的关键状态，都可以作为业务指标来监控。但是由于业务指标往往不具有通用性，所以，需要手动在程序里埋点打桩。因此，对业务指标的监控必然是侵入性的。

无论业务系统如何复杂，监控指标如何眼花缭乱，但万变不离其宗，监控的目的无非是为了解服务运行状况、发现服务故障和帮助定位故障原因。为了达成这个目的，Google SRE 总结的监控四个黄金指标对我们添加监控具有非常重要的指导意义。

![](https://i.postimg.cc/cHS5gHMz/Google-SRE.png)

下文我们即会从四个黄金指标的维度展开，浅述监控体系中常用的监控指标。

# 错误

错误是指当前系统发生的错误请求和错误率，是需要在添加监控时首要关注的指标。基础监控维度的宕机、磁盘（坏盘或文件系统错误）、进程或端口挂掉、网络丢包等故障。

业务监控则较为复杂，可能包含以下方面：

- 核心功能处理错误，每种系统都有特定的核心功能，比如 HDFS 的文件块读写、Zookeeper 对 Key 的读写和修改操作。

- 基础功能单元丢失或异常，这里的基础功能单元是指一个系统功能上的基本单位，例如 HDFS 的 Block、Kafka 的 Message，这种基础数据的丢失一般都会对业务功能造成直接的影响。

- Master 故障，对于中心化的分布式系统来说，Master 的健康状况都是重中之重。例如 HDFS 的 NameNode、Zookeeper 的 Leader，ElasticSearch 的 MasterNode。

- 可用节点数，对于分布式系统来说，可用节点数也是非常重要的，比如 Zookeeper、ETCD 等系统需要满足可用节点数大于不可用节点数才能保证功能的正常。

除白盒监控外，主要功能或接口、以及内部存在明显边界的功能模块和上游依赖模块，都应该添加黑盒端到端监控。

## MTTF

- MTTF, Mean Time To Failure，系统平均运行多长时间才发生故障，越长越好

MTTR,Mean Time To Recover, 故障平均修复时间，越短越好

可用性计算公式，Availability= MTTF /（MTTF+MTTR）

MTTF, Mean Time To Failure，系统平均运行多长时间才发生故障，越长越好
MTTR,Mean Time To Recover, 故障平均修复时间，越短越好
可用性计算公式，Availability= MTTF /（MTTF+MTTR）

# 延迟

从客户端来看，延迟就是从发送请求到接收响应的整体耗时，包括：请求的网络耗时，请求在服务端的处理耗时以及响应的网络耗时。吞吐量则是服务在一定的并发下，每秒可以处理的请求数。

服务延迟的上升不仅仅体现在用户体验的下降，也有可能会导致请求堆积并最终演变为整个业务系统的雪崩。以下为延迟指标的主要关注点：

- 基础监控：IO 等待、网络延迟；
- 业务监控：业务相关指标主要需要关注核心功能的响应时长。比如 Zookeeper 的延迟指标 zk_avg_latency，ElasticSearch 的索引、搜索延迟和慢查询。

与错误指标类似，白盒延迟指标通常仅能代表系统内部延迟，建议为主要功能或接口添加黑盒监控来采集端到端的延迟指标。

## RT | 响应时间

响应时间即 RT，处理一次请求所需要的平均处理时间。对于 RT，客户端和服务端是大不相同的，因为请求从客户端到服务端，需要经过广域网，所以客户端 RT 往往远大于服务端 RT，同时客户端的 RT 往往决定着用户的真实体验，服务端 RT 往往是评估我们系统好坏的一个关键因素。

假设我们的服务端只有一个线程，那么所有的请求都是串行执行，我们可以很简单的算出系统的 QPS，也就是：QPS = 1000ms/RT。假设一个 RT 过程中 CPU 计算的时间为 49ms，CPU Wait Time 为 200ms，那么 QPS 就为 1000/49+200 = 4.01。CPU Time 就是一次请求中，实际用到计算资源。CPU Time 的消耗是全流程的，涉及到请求到应用服务器，再从应用服务器返回的全过程。实际上这取决于你的计算的复杂度。

CPU Wait Time 是一次请求过程中对于 IO 的操作，CPU 这段时间可以理解为空闲的，那么此时要尽量利用这些空闲时间，也就是增加线程数。

CPU 利用率是业务系统利用到 CPU 的比率，因为往往一个系统上会有一些其他的线程，这些线程会和 CPU 竞争计算资源，那么此时留给业务的计算资源比例就会下降，典型的像，GC 线程的 GC 过程、锁的竞争过程都是消耗 CPU 的过程。甚至一些 IO 的瓶颈，也会导致 CPU 利用率下降(CPU 都在 Wait IO，利用率当然不高)。

用户平均请求等待时间（Time per request）

计算公式：处理完成所有请求数所花费的时间/（总请求数 / 并发用户数），即
Time per request = Time taken for tests /（Complete requests / Concurrency Level）

服务器平均请求等待时间（Time per request: across all concurrent requests）
计算公式：处理完成所有请求数所花费的时间 / 总请求数，即
Time taken for / testsComplete requests
可以看到，它是吞吐率的倒数。
同时，它也=用户平均请求等待时间/并发用户数，即
Time per request / Concurrency Level

# 流量

流量指标可以指系统层面的网络和磁盘 IO，服务层面的 QpS、PV 和 UV 等数据。流量和突增或突减都可能预示着系统可能出现问题（攻击事件、系统故障…）。以下为流量主要关注的方面：

- 基础监控：磁盘和网卡 IO；
- 业务监控：核心功能流量，例如通过 QpS/PV/UV 等通常能够代表 Web 服务的流量，而 ElasticSearch 的流量可用索引创建速率、搜索速率表示。

吞吐量（Throughout）与时延（Latency）是衡量软件系统的最常见的两个指标，系统的吞度量（承压能力）与请求对 CPU 的消耗、外部接口、IO 等等紧密关联；单个请求对 CPU 消耗越高，外部系统接口、IO 影响速度越慢，系统吞吐能力越低，反之越高。吞吐量与时延是天生矛盾的，吞吐量增加也就意味着同一时间请求并发的增加；而由于资源的限制，同一时刻可以处理的请求数是固定的，取决于整个请求处理过程中最小的那个环节。当并发请求数大于这个值时，就会有请求排队等待被处理。所以，要提升服务的吞吐量，必定会增加整体延迟。另外，如果服务的延迟（单个请求的耗时）减少，由于排队的请求的等待时间也减少了，所以吞吐量会上升。

我们通常说的网站流量(traffic)就是指网站的访问量，是用来描述访问一个网站的用户数量以及用户所浏览的网页数量等指标，常用的统计指标包括网站的独立用户数量、总用户数量(含重复访问者)、网页浏览数量、每个用户的页面浏览数量、用户在网站的平均停留时间等。

网站访问量的衡量标准一个是 IP,另一个是 PV,常以日为标准,即日独立 IP 和 PV 来计算.

    访问数(IP)：即Internet Protocol,指独立IP数。00:00-24:00内相同IP地址只被计算一次。

    综合浏览量(PV)：即Page View, 即页面浏览量或点击量，用户每次刷新即被计算一次。

    二者的联系与区别：PV高不一定代表来访者多；PV与来访者的数量成正比，但是PV并不直接决定页面的真实来访者数量。比如一个网站就你一个人进来，通过不断的刷新页面，也可以制造出非常高的PV。

IP 是一个反映网络虚拟地址对象的概念，独立用户是一个反映实际使用者的概念，每个独立用户相对于每个 IP，更加准确地对应一个实际的浏览者。使用独立用户作为统计量，可以更加准确的了解单位时间内实际上有多少个访问者来到了相应的页面。

一个独立 IP 可以产生多个 PV,所以 PV 个数>=IP 个数。

    PV(Page View)值：是指一定时间范围内所有浏览该网站的访问者请求的页面数量之合。(例如：该网站一天有500个访问者，每个访问者浏览的页面数量平均为8页，则每天的PV是500×8=4000)

    Hits值：是指对每个页面元素的请求数量。(一个页面中任何一个图片或者flash文件都算是一个页面元素)

    日浏览字节数：即日流量，是指一天内，访问者请求的所有页面元素的字节数之和。

计算带宽大小需要关注两个指标：峰值流量和页面的平均大小。举个例子说明下吧:

    假设网站的峰值流量是平均流量的5倍(当然，这只是一个假设，具体实施我们需要视自己情况而定)；

    假设每次访问的平均页面大小是200K字节；

    假设网站的预期目标是每天50W PV的访问量。

我们的计算开始：50W

PV 如果在一天内平均分布，折合到每秒大概是 50W/(24*60*60)=6 次访问，按照我们之前的假设平均页面大小是 200K 字节计算，这 6 次访问总

共就是 1200K 字节(需要注意的是这个地方是字节)，字节的单位是 Byte，而带宽的单位是 bit，1Byte=8bit，因此 1200K

Byte 大概就是 9600K

bit，也就是 9Mbps(1M=1024K)。在实际的网站运行过程中，我们的网站必须要在峰值流量时保持正常的访问，这里就会用到我们之前的假设，峰

值流量是平均流量的 5 倍，按照这个计算，实际需要的带宽大约在 9Mbps\*5=45Mbps 左右。

**具体的计算公式是：网站独享带宽=一天总的 PV 值 ÷ 一天总时间(换算到 S\*平均页面大小(单位 KB)\* 8**

     这个计算结果的前提是我们之前的三条假设，而在实际运行中，由于缓存、网站提供下载、图片较多、网站白天夜里访问量不同等原因，这个结果可能并不是很理想。所以这个算法只能算是一个大概的算法了。

eg. 10w pv,页面大小 1M，带宽=10,0000/86400*1M*8 = 9.26Mbps

## TPS & QPS

TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS 包括一条消息入和一条消息出，加上一次用户数据库访问。（业务 TPS = CAPS × 每个呼叫平均 TPS）。TPS 是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力最低模块的 TPS 值。

QPS：每秒查询率 QPS 是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。

对应 fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。

## QPS & TPS & RPS

并发连接数（The number of concurrent connections）

概念：某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。

并发用户数（The number of concurrent users，Concurrency Level）

概念：要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。

QPS(Queries Per Second)每秒能处理查询数目。是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。QPS 是每秒钟处理完请求的次数。这里的请求不是指一个查询或者数据库查询，是包括一个业务逻辑的整个流程，也就是说每秒钟响应的请求次数。

TPS(Transactions Per Second)指每秒处理的事务数目；事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。TPS 的过程包括：客户端请求服务端、服务端内部处理、服务端返回客户端，客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息作出的评估分。

RPS(Requests Per Second) | 吞吐率: 服务器并发处理能力的量化描述，单位是 reqs/s，指的是某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。

### 访问量指标

PV  即 page view，页面浏览量   用户每一次对网站中的每个页面访问均被记录 1 次。用户对同一页面的多次刷新，访问量累计。

UV  即 Unique visitor，独立访客   通过客户端的 cookies 实现。即同一页面，客户端多次点击只计算一次，访问量不累计。

IP  即 Internet Protocol，本意本是指网络协议，在数据统计这块指通过 ip 的访问量。   即同一页面，客户端使用同一个 IP 访问多次只计算一次，访问量不累计。

# 饱和度

饱和度可以理解为服务的利用率，可以代表系统承受的压力。所以饱和度与流量息息相关，流量的上升一般也会导致饱和度的上升。通常情况下，每种业务系统都应该有各自的饱和度指标。在很多业务系统中，消息队列长度是一个比较重要的饱和度指标，除此之外 CPU、内存、磁盘、网络等系统资源利用率也可以作为饱和度的一种体现方式。

基础监控自然包含 CPU、内存、磁盘和网络利用率、内存堆栈利用率、文件句柄数、TCP 连接数等；业务监控：

- 基础功能单元使用率，大多数系统对其基础的功能单元都有其处理能力的上限，接近或达到该上限时可能会导致服务的错误、延迟增大。例如 HDFS 的 Block 数量上升会导致 NameNode 堆内存使用率上升，Kafka 的 Topics 和 Partitions 的数量、Zookeeper 的 node 数的上升都会对系统产生压力。

- 消息队列长度，不少系统采用消息队列存放待处理数据，所以消息队列长度在一定程度上可以代表系统的繁忙程度。如 ElasticSearch、HDFS 等都有队列长度相关指标可供采集。

# TBD

- [根据 PV 计算带宽及根据 PV 算并发](http://www.tuicool.com/articles/aqi6Znr)

- [性能测试中服务器关键性能指标浅析](http://www.tuicool.com/articles/B3IFBbe)
